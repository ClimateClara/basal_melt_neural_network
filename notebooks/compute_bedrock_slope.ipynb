{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032743bc-0a46-41dd-8cf7-c759078fca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Jun 09 14:36 2021\n",
    "\n",
    "Prepare bedrock slope for use in the neural network\n",
    "\n",
    "Author: @claraburgard\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1756e-ce85-408f-803d-48b24131e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79e103-f4c9-4e4c-977b-2e90fbede60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run = 'OPM016'\n",
    "inputpath_data='/bettik/burgardc/SCRIPTS/basal_melt_param/data/interim/NEMO_eORCA025.L121_'+nemo_run+'_ANT_STEREO/'\n",
    "inputpath_mask = '/bettik/burgardc/SCRIPTS/basal_melt_param/data/interim/ANTARCTICA_IS_MASKS/nemo_5km_'+nemo_run+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc66a4-835b-4a94-bd6e-37549b34e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_domain_stereo(var_to_cut, map_lim_x, map_lim_y):\n",
    "    var_cutted = var_to_cut.sel(x=var_to_cut.x.where(in_range(var_to_cut.x,map_lim_x),drop=True), y=var_to_cut.y.where(in_range(var_to_cut.y,map_lim_y),drop=True))\n",
    "    return var_cutted\n",
    "\n",
    "def in_range(in_xy,txy):\n",
    "    return ((in_xy >= min(txy)) & (in_xy < max(txy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccfa9e-a01f-4266-b96d-b1a928f3909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_isf_orig = xr.open_dataset(inputpath_mask+'nemo_5km_isf_masks_and_info_and_distance_new.nc')\n",
    "nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "file_isf_nonnan = file_isf_orig.sel(Nisf=nonnan_Nisf)\n",
    "large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "file_isf = file_isf_nonnan.sel(Nisf=large_isf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51862f3-81ca-4847-8e4a-9a1c38ed2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lim = [-3000000,3000000]\n",
    "file_mask_orig = xr.open_dataset(inputpath_data+'other_mask_vars_Ant_stereo.nc')\n",
    "file_mask_orig_cut = cut_domain_stereo(file_mask_orig, map_lim, map_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def40da3-5979-4e61-967d-6d9bc5615dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_bed_orig = file_mask_orig_cut['bathy_metry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277cba5-08c2-42af-bc1d-36d78e05f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_slope_one_dimension(input_da, shifted_plus, shifted_minus, dx):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the basal slope at each point.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_da : xr.DataArray\n",
    "        Array where slope needs to be checked. For example: ice draft.\n",
    "    shifted_plus : xr.DataArray\n",
    "        Shifted version (positive direction) of input_da.\n",
    "    shifted_minus : xr.DataArray\n",
    "        Shifted version (negative direction) of input_da.\n",
    "    dx : float\n",
    "        Step in the coordinate along which input_da was shifted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    slope: xr.DataArray\n",
    "        slope along that coordinate, is 0 if nan\n",
    "    \"\"\"\n",
    "    \n",
    "    # check the direction in both dim directions\n",
    "    slope_both = (shifted_minus - shifted_plus) / np.sqrt((2 * dx) ** 2)\n",
    "    # if x+1 is nan, only take x - (x-1)\n",
    "    slope_right = (input_da - shifted_plus) / np.sqrt(dx ** 2)\n",
    "    # if x-1 is nan, only take x+1 - x\n",
    "    slope_left = (shifted_minus - input_da) / np.sqrt(dx ** 2)\n",
    "    # combine all of the above\n",
    "    slope = slope_both.combine_first(slope_right).combine_first(slope_left)\n",
    "    # set rest to 0\n",
    "    slope = slope.where(np.isfinite(slope), 0)\n",
    "    return slope\n",
    "\n",
    "\n",
    "def compute_alpha_appenB(kisf, plume_var_of_int, ice_draft_neg, dx, dy):   \n",
    "\n",
    "    \"\"\"\n",
    "    Compute alphas like in Appendix B of Favier et al., 2019 TCDiscussions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    kisf : int\n",
    "        ID of the ice shelf of interest\n",
    "    plume_var_of_int : xr.Dataset\n",
    "        Dataset containing ``'ISF_mask'`` and ``'dIF'``\n",
    "    ice_draft_neg : xr.DataArray\n",
    "        Ice draft depth in m. Negative downwards.\n",
    "    dx : float\n",
    "        Grid spacing in the x-direction\n",
    "    dy : float\n",
    "        Grid spacing in the y-direction\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    go_back_to_whole_grid_local_alpha: xr.DataArray\n",
    "        Local slope angle in rad for each point.\n",
    "    \"\"\"\n",
    "    \n",
    "    # cut out the ice shelf of interest\n",
    "    draft_isf = ice_draft_neg.where(plume_var_of_int['ISF_mask'] == kisf, drop=True)\n",
    "\n",
    "    shiftedx_minus = draft_isf.shift(x=-1)\n",
    "    shiftedx_plus = draft_isf.shift(x=1)\n",
    "    xslope = check_slope_one_dimension(draft_isf, shiftedx_plus, shiftedx_minus, dx)\n",
    "\n",
    "    shiftedy_minus = draft_isf.shift(y=-1)\n",
    "    shiftedy_plus = draft_isf.shift(y=1)\n",
    "    yslope = check_slope_one_dimension(draft_isf, shiftedy_plus, shiftedy_minus, dy)\n",
    "\n",
    "    dIF_isf = plume_var_of_int['dIF'].where(plume_var_of_int['ISF_mask'] == kisf)\n",
    "    dIF_isf_corr = dIF_isf.where(dIF_isf/2500 < 1,1) #check again with Nico, if I understood it right (MIN to avoid strong frontal slope)\n",
    "\n",
    "    local_alpha = np.arctan(np.sqrt(xslope ** 2 + yslope ** 2)) * dIF_isf_corr\n",
    "\n",
    "    go_back_to_whole_grid_local_alpha = local_alpha.reindex_like(plume_var_of_int['ISF_mask'])\n",
    "\n",
    "    return go_back_to_whole_grid_local_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2033ad-cd7e-4a06-b20e-f123eec84846",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = file_isf.x[2] - file_isf.x[1]\n",
    "dy = file_isf.y[2] - file_isf.y[1]\n",
    "\n",
    "bedrock_slope = None\n",
    "for kisf in tqdm(file_isf.Nisf):\n",
    "    #print(kisf.values)\n",
    "    bb_sl = compute_alpha_appenB(kisf, file_isf, -1*file_bed_orig, abs(dx), abs(dy))\n",
    "    if bedrock_slope is None:\n",
    "        bedrock_slope = bb_sl\n",
    "    else:\n",
    "        bedrock_slope = bedrock_slope.combine_first(bb_sl)\n",
    "bedrock_slope_smooth = bedrock_slope.reindex_like(file_isf)\n",
    "bedrock_slope_smooth.to_dataset(name='bedrock_slope').to_netcdf(inputpath_mask+'nemo_5km_bedrock_slope.nc','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3d93f-951f-4843-bf5a-028ccebf1ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnet",
   "language": "python",
   "name": "neuralnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ffe6b-dab3-4e2b-96e9-676bcbb2f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Apr 26 12:20 2022\n",
    "\n",
    "Prepare input for a given experiment (marked by timetag)\n",
    "\n",
    "Author: @claraburgard\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21642825-053b-4875-8446-a5d2f0761a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from dask import delayed\n",
    "\n",
    "import distributed\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "from basal_melt_neural_networks.constants import *\n",
    "import basal_melt_neural_networks.diagnostic_functions as diag\n",
    "import basal_melt_neural_networks.data_formatting as dfmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfeb83c-ce58-4a0b-98c5-0c23484bee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(n_workers=8, dashboard_address=':8795', local_directory='/tmp', memory_limit='4GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c0bf2-a45a-4de4-8908-6617cc6a9a83",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15d70c-1525-4d12-9ba6-cb87849fd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = ['OPM006', 'OPM016', 'OPM018', 'OPM031-2']\n",
    "TS_input = 'whole_prof' #'whole_prof' #'extrapolated'\n",
    "isf_list = [10, 11, 12, 13, 18, 21, 22, 23, 24, 25, 30, 31, 33, 38, 39, 40, 42, 43, 44, 45, 47, 48, 51, 52, 53, 54, 55, 58, 61, 65, 66, 69, 70, 71, 73, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde3653-a856-4dd2-ade0-a25a8de4d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data = '/bettik/burgardc/DATA/NN_PARAM/interim/INPUT_DATA/'\n",
    "outputpath_nn_models = '/bettik/burgardc/DATA/NN_PARAM/interim/NN_MODELS/'\n",
    "outputpath_doc = '/bettik/burgardc/SCRIPTS/basal_melt_neural_networks/custom_doc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c4a0c-4ee5-4af6-8e5e-8258483fa31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_timetag = False\n",
    "if new_timetag:\n",
    "    datetag_dt = datetime.datetime.today()\n",
    "    timetag_dt = datetime.datetime.now()\n",
    "    timetag = str(datetag_dt.year)+str(datetag_dt.month).zfill(2)+str(datetag_dt.day).zfill(2)+'-'+str(timetag_dt.hour).zfill(2)+str(timetag_dt.minute).zfill(2)\n",
    "else:\n",
    "    #timetag = '20220422-1055'\n",
    "    timetag = '20220425-1050'\n",
    "\n",
    "new_path_model = outputpath_nn_models+timetag+'/'\n",
    "if not os.path.isdir(new_path_model):\n",
    "    print(\"I did not find this folder (\"+timetag+\") in model folder so I created a new one, I hope that's ok!\")\n",
    "    os.mkdir(new_path_model)\n",
    "else:\n",
    "    print(\"This folder (\"+timetag+\") in model folder exists already!\")\n",
    "\n",
    "new_path_doc = outputpath_doc+timetag+'/'\n",
    "if not os.path.isdir(new_path_doc):\n",
    "    print(\"I did not find this folder (\"+timetag+\") in doc folder so I created a new one, I hope that's ok!\")\n",
    "    os.mkdir(new_path_doc)\n",
    "else:\n",
    "    print(\"This folder (\"+timetag+\") in doc folder exists already!\")\n",
    "    \n",
    "new_path_input = inputpath_data+timetag+'/'\n",
    "if not os.path.isdir(new_path_input):\n",
    "    print(\"I did not find this folder (\"+timetag+\") in input folder so I created a new one, I hope that's ok!\")\n",
    "    os.mkdir(new_path_input)\n",
    "else:\n",
    "    print(\"This folder (\"+timetag+\") in input folder exists already!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd90827-b6a2-41cd-816b-fb2f8438762d",
   "metadata": {},
   "source": [
    "SAVE SELECTED DATA TO ONE NETCDF (FROM RUN LIST AND ISF LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29531f3-00b8-446f-a050-79afd58e752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TS_input == 'whole_prof':\n",
    "    csv_path = inputpath_data + 'WHOLE_PROF/'\n",
    "elif TS_input == 'extrapolated':\n",
    "    csv_path = inputpath_data + 'EXTRAPOLATED_ISFDRAFT/'\n",
    "\n",
    "all_input_df = None        \n",
    "    \n",
    "for nemo_run in run_list:\n",
    "    \n",
    "    for kisf in tqdm(isf_list): \n",
    "    #for kisf in tqdm([23,66]): \n",
    "    #for kisf in tqdm([23]): \n",
    "        clean_df_nrun_kisf = pd.read_csv(csv_path + 'dataframe_input_isf'+str(kisf).zfill(3)+'_'+nemo_run+'.csv',index_col=[0,1,2])\n",
    "        clean_df_nrun_kisf.reset_index(drop=True, inplace=True)\n",
    "        clean_ds_nrun_kisf = clean_df_nrun_kisf.to_xarray()\n",
    "\n",
    "        if all_input_df is None:\n",
    "            all_input_df = clean_ds_nrun_kisf.copy()\n",
    "        else:\n",
    "            #print(clean_ds_nrun_kisf.index)\n",
    "            #print(all_input_df.index.max())\n",
    "            new_index = clean_ds_nrun_kisf.index.values + all_input_df.index.max().values+1\n",
    "            #print(new_index)\n",
    "            clean_ds_nrun_kisf = clean_ds_nrun_kisf.assign_coords({'index': new_index})\n",
    "            all_input_df = xr.concat([all_input_df, clean_ds_nrun_kisf], dim='index') \n",
    "\n",
    "all_input_df.to_netcdf(new_path_input + 'dataset_input_'+timetag+'.nc','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bafe5f-fef4-4904-a4ad-d8b62b7b106b",
   "metadata": {},
   "source": [
    "DIVIDE INTO TRAIN AND TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ba499-50c9-40d1-be8d-8b9d8f7a188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_df = xr.open_mfdataset(new_path_input + 'dataset_input_'+timetag+'.nc')#.load()#.chunk({'index': 10000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac59c32-5df9-45b3-b570-c556ee949545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frac = 0.7\n",
    "\n",
    "all_indexes = all_input_df.index\n",
    "random_sample = np.random.choice(all_indexes, size=np.round(len(all_indexes)*0.7).astype(int), replace=False)\n",
    "\n",
    "data_train = all_input_df.sel(index=random_sample)\n",
    "data_test = all_input_df.drop_sel(index=random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b628ae-bbbb-4fa1-9b39-eca470e618dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['melt_m_ice_per_y']\n",
    "x_train = data_train.drop_vars(['melt_m_ice_per_y'])\n",
    "\n",
    "y_test = data_test['melt_m_ice_per_y']\n",
    "x_test = data_test.drop_vars(['melt_m_ice_per_y'])\n",
    "\n",
    "print('Original data shape was : ', print_shape_xr_ds(all_input_df))\n",
    "print('x_train : ',dfmt.print_shape_xr_ds(x_train), 'y_train : ',len(y_train))\n",
    "print('x_test  : ',dfmt.print_shape_xr_ds(x_test),  'y_test  : ',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0832b79-e570-4433-962d-355a05b436d6",
   "metadata": {},
   "source": [
    "DATA NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85e311-e3bc-40d2-882e-0479f343c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_method = 'interquart' #'std', 'interquart', 'minmax'\n",
    "\n",
    "x_mean = x_train.mean()\n",
    "y_mean = y_train.mean()\n",
    "\n",
    "if norm_method == 'std':\n",
    "    x_range  = x_train.std()\n",
    "    y_range  = y_train.std()\n",
    "elif norm_method == 'interquart':\n",
    "    x_range  = x_train.quantile(0.9) - x_train.quantile(0.1)\n",
    "    y_range  = y_train.quantile(0.9) - y_train.quantile(0.1)\n",
    "elif norm_method == 'minmax':\n",
    "    x_range  = x_train.max() - x_train.min() \n",
    "    y_range  = y_train.max() - y_train.min() \n",
    "    \n",
    "x_train_norm = (x_train - x_mean)/x_range\n",
    "x_test_norm = (x_test - x_mean)/x_range\n",
    "\n",
    "y_train_norm = (y_train - y_mean)/y_range\n",
    "y_test_norm = (y_test - y_mean)/y_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c94d11-abf0-48ee-8172-5be05c2f66da",
   "metadata": {},
   "source": [
    "Write normalization factors to netcdf (to be used in application of the NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb96721-7273-44fc-87ce-6cc59b48a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ds = xr.merge([x_mean,y_mean])\n",
    "mean_ds = mean_ds.assign_coords({'metric': 'mean_vars'})\n",
    "range_ds = xr.merge([x_range,y_range])\n",
    "range_ds = range_ds.assign_coords({'metric': 'std_vars'})\n",
    "summary_ds = xr.concat([mean_ds, range_ds], dim='metric')\n",
    "\n",
    "summary_ds.to_netcdf(new_path_model + 'dataset_norm_training_factors_'+timetag+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7442ec7-1779-420a-9ee6-b48e8a65360a",
   "metadata": {},
   "source": [
    "Write training and test dataset to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1783b7-a8f4-4819-9664-5df9c4d0a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_norm = xr.merge([x_train_norm,y_train_norm])\n",
    "data_train_norm.to_netcdf(new_path_model + 'dataset_norm_training_data_'+timetag+'.nc', 'w')\n",
    "data_test_norm = xr.merge([x_test_norm,y_test_norm])\n",
    "data_test_norm.to_netcdf(new_path_model + 'dataset_norm_test_data_'+timetag+'.nc', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5cafa-fddf-4530-a4ac-4022a6660f1a",
   "metadata": {},
   "source": [
    "WRITE INFOS ABOUT TRAINING DATA INTO THE DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a61d13-4655-48b3-bb5e-02274271b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_path_doc+'info_'+timetag+'.log','w') as file:\n",
    "    file.write('Timetag: '+timetag+' \\n')\n",
    "    file.write('----- DATA ----- \\n')\n",
    "    file.write('Taraining data from: '+str(run_list)+'\\n')\n",
    "    file.write('Ice shelves: '+str(isf_list)+'\\n')\n",
    "    file.write('Input T and S format: '+TS_input+'\\n')\n",
    "    file.write('Norm method: '+norm_method+'\\n')\n",
    "    #file.write('Original data shape was : '+str(all_input_df.shape)+'\\n')\n",
    "    file.write('x_train : '+str(print_shape_xr_ds(x_train_norm))+', y_train : '+str(y_train_norm.values.shape)+'\\n')\n",
    "    file.write('x_test  : '+str(print_shape_xr_ds(x_test_norm))+', y_test  : '+str(y_test_norm.values.shape)+'\\n') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

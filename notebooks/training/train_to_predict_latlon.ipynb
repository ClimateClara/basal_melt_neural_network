{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610056d1-c9a5-4d36-a7bf-81701e4b0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Oct 21 16:58 2022\n",
    "\n",
    "Look if with training I can match exactly latlon\n",
    "\n",
    "Author: Clara Burgard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919eb0d8-b9f6-4e73-b789-fe4bdfdf0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import basal_melt_neural_networks.model_functions as modf\n",
    "import basal_melt_neural_networks.prep_input_data as indat\n",
    "import basal_melt_neural_networks.postprocessing_functions as pp\n",
    "\n",
    "import xgboost\n",
    "import shap\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf012d-c6fe-440c-8a83-dc4c1cf58797",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343ebbe-d4c2-4374-a5d8-6aef471bbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### READ IN OPTIONS\n",
    "\n",
    "mod_size = 'medium' #'mini', 'small', 'medium', 'large', 'extra_large'\n",
    "tblock_out = 1\n",
    "isf_out = 0\n",
    "TS_opt = 'extrap' # extrap, whole, thermocline\n",
    "norm_method = 'std' # std, interquart, minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d6ccd-6d61-4a71-9e1b-c4c111839ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### READ IN DATA\n",
    "\n",
    "inputpath_data = '/bettik/burgardc/DATA/NN_PARAM/interim/INPUT_DATA/'\n",
    "outputpath_nn_models = '/bettik/burgardc/DATA/NN_PARAM/interim/NN_MODELS/'\n",
    "outputpath_doc = '/bettik/burgardc/SCRIPTS/basal_melt_neural_networks/custom_doc/'\n",
    "\n",
    "tblock_dim = range(1,14)\n",
    "isf_dim = [10,11,12,13,18,22,23,24,25,30,31,33,38,39,40,42,43,44,45,47,48,51,52,53,54,55,58,61,65,66,69,70,71,73,75]\n",
    "\n",
    "if (tblock_out > 0) and (isf_out == 0):\n",
    "    path_model = outputpath_nn_models+'CV_TBLOCK/'\n",
    "    \n",
    "elif (isf_out > 0) and (tblock_out == 0):\n",
    "    path_model = outputpath_nn_models+'CV_ISF/'\n",
    "    \n",
    "else:\n",
    "    print(\"I do not know what to do with both tblock and isf left out! \")\n",
    "\n",
    "#new_path_doc = outputpath_doc+timetag+'/'\n",
    "#if not os.path.isdir(new_path_doc):\n",
    "#    print(\"I did not find this folder (\"+timetag+\") in doc folder! :( \")\n",
    "\n",
    "inputpath_CVinput = inputpath_data+'EXTRAPOLATED_ISFDRAFT_CHUNKS_CV/'\n",
    "    \n",
    "input_data_train_norm = xr.open_dataset(inputpath_CVinput + 'train_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "input_data_val_norm = xr.open_dataset(inputpath_CVinput + 'val_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc') \n",
    "latlon_train_norm = xr.open_dataset(inputpath_CVinput + 'trainlatlon_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "latlon_val_norm = xr.open_dataset(inputpath_CVinput + 'vallatlon_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd03ed8-67c5-49be-8e8e-2ebc9aba1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare input and target\n",
    "\n",
    "x_train_norm = input_data_train_norm.drop_vars(['melt_m_ice_per_y','theta_in','salinity_in']).sel(norm_method=norm_method).to_array().load()\n",
    "y_train_norm = latlon_train_norm.drop_vars(['salinity_in']).sel(norm_method=norm_method).to_array().load()\n",
    "\n",
    "x_val_norm = input_data_val_norm.drop_vars(['melt_m_ice_per_y','theta_in','salinity_in']).sel(norm_method=norm_method).to_array().load()\n",
    "y_val_norm = latlon_val_norm.drop_vars(['salinity_in']).sel(norm_method=norm_method).to_array().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cee68-d3fa-4bf6-be77-c450cff05021",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_norm.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c871d-dc92-4e8c-bdf1-9fcaf89993af",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TRAIN THE MODEL\n",
    "\n",
    "input_size = x_train_norm.values.shape[0]\n",
    "activ_fct = 'relu' #LeakyReLU\n",
    "epoch_nb = 35\n",
    "batch_siz = 512\n",
    "\n",
    "model = modf.get_model(mod_size, input_size, activ_fct, 2)\n",
    "\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.0000001, min_delta=0.0005) #, min_delta=0.1\n",
    "            \n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    #min_delta=0.000001,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "time_start0 = datetime.datetime.now()\n",
    "print(time_start0)\n",
    "\n",
    "history = model.fit(x_train_norm.T.values,\n",
    "                    y_train_norm.T.values,\n",
    "                    epochs          = epoch_nb,\n",
    "                    batch_size      = batch_siz,\n",
    "                    validation_data = (x_val_norm.T.values, y_val_norm.T.values),\n",
    "                   callbacks=[reduce_lr, early_stop])\n",
    "time_end = time.time()\n",
    "timelength = time_end - time_start\n",
    "\n",
    "time_end0 = datetime.datetime.now()\n",
    "print(time_end0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd59b8-513f-4ac3-be56-4da7361a6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path_model + 'model_medium_latlon.h5')\n",
    "# maybe limit it to 60 epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271737a-a0ae-4046-894a-2bb168bb1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(path_model + 'model_medium_latlon.h5')\n",
    "y_out_norm = model.predict(x_val_norm.T.values)\n",
    "y_out_norm_xr = xr.DataArray(data=y_out_norm.squeeze()).rename({'dim_0': 'index'})\n",
    "y_out_norm_xr = y_out_norm_xr.assign_coords({'index': x_val_norm.index,'dim_1': ['latitude','longitude']})\n",
    "\n",
    "norm_metrics_file = xr.open_dataset(inputpath_CVinput + 'metricslatlon_norm_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "norm_metrics = norm_metrics_file.sel(norm_method=norm_method).drop('norm_method').to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4005b-cc7d-41f9-9367-f9cd2053dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalise the output\n",
    "lat_out = pp.denormalise_vars(y_out_norm_xr.sel(dim_1='latitude'), \n",
    "                         norm_metrics['latitude'].loc['mean_vars'],\n",
    "                         norm_metrics['latitude'].loc['range_vars'])\n",
    "\n",
    "lat_target = pp.denormalise_vars(latlon_val_norm['latitude'].sel(norm_method='std'), \n",
    "                         norm_metrics['latitude'].loc['mean_vars'],\n",
    "                         norm_metrics['latitude'].loc['range_vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d920114-66a1-4336-bd9e-654d9d4cd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_out = pp.denormalise_vars(y_out_norm_xr.sel(dim_1='longitude'), \n",
    "                         norm_metrics['longitude'].loc['mean_vars'],\n",
    "                         norm_metrics['longitude'].loc['range_vars'])\n",
    "\n",
    "lon_target = pp.denormalise_vars(latlon_val_norm['longitude'].sel(norm_method='std'), \n",
    "                         norm_metrics['longitude'].loc['mean_vars'],\n",
    "                         norm_metrics['longitude'].loc['range_vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80d503-22ca-4249-b48a-4c2ed8e1fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_out_pd_s = pd.Series(lat_out.values,index=latlon_val_norm.index,name='predicted_lat') \n",
    "lat_target_pd_s = pd.Series(lat_target.values,index=input_data_val_norm.index,name='reference_lat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226fc82-452a-44d0-957e-1a5cfc759ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_out_pd_s = pd.Series(lon_out.values,index=latlon_val_norm.index,name='predicted_lon') \n",
    "lon_target_pd_s = pd.Series(lon_target.values,index=input_data_val_norm.index,name='reference_lon') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b80a69-eae5-4f1e-97ad-50da3c7e82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = range(-180,180)\n",
    "yy = range(-90,-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcd0bf-4f9e-4bf4-b693-93d05db66a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lon_out_pd_s,lon_target_pd_s,s=5,alpha=0.2)\n",
    "plt.plot(xx,xx,'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801cf1f-b393-448f-ac24-ee20d9a142c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(lat_out_pd_s,lat_target_pd_s,s=5,alpha=0.2)\n",
    "plt.plot(yy,yy,'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea154274-7881-496a-a98e-f2acb70b215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an XGBoost model\n",
    "X, y = shap.datasets.boston()\n",
    "model = xgboost.XGBRegressor().fit(x_train_norm.T.values, y_train_norm.T.values)\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(x_train_norm.T.values)\n",
    "#shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2acf2-db7e-4e92-b932-9fb467c1a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d7bf8-7bdb-4791-a5a7-c4ce5bcbd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    print(i,x_train_norm['variable'].isel(variable=i).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a0319-393c-4388-a7fa-cacccf36dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f4fecc-4d72-417d-85e3-abed75b36e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a31e6-ff63-4ee4-a302-e19cc59cff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da011c0-f54c-4e7e-aa64-a5cb67ad3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put some order in the file\n",
    "lat_out_xr = lat_out_pd_s.to_xarray()\n",
    "lat_target_xr = lat_target_pd_s.to_xarray()\n",
    "lat_to_compare = xr.merge([lat_out_xr.T, lat_target_xr.T]).sortby('y')\n",
    "\n",
    "lon_out_xr = lon_out_pd_s.to_xarray()\n",
    "lon_target_xr = lon_target_pd_s.to_xarray()\n",
    "lon_to_compare = xr.merge([lon_out_xr.T, lon_target_xr.T]).sortby('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db5666-b452-437a-b925-5f39cf1b1070",
   "metadata": {},
   "source": [
    "TRY SHUFFLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0419a0a-4846-4ff5-8f06-b28b06cdb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_isf_area = x_val_norm.sel(variable='isf_area').copy()\n",
    "np.random.shuffle(shuffled_isf_area.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4e05d-b5e7-49cc-bc51-fd0db19b0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_norm.sel(variable='isf_area').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6f137-cdd0-4c16-afe1-b2f3fb58de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_isf_area.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a0a8d-9335-4ecb-b2b1-fc45d5effd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_isf_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df2630-0107-445a-9ff7-3c74cbcfb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_norm_shuffled = xr.concat([x_val_norm.drop_sel(variable='isf_area').copy(),shuffled_isf_area], dim='variable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98022f1a-64cc-42c6-84b4-ce0b06e4894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_norm_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d258522-c41a-4b77-913d-823bed15d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(path_model + 'model_medium_latlon.h5')\n",
    "y_out_shuffled_norm = model.predict(x_val_norm.T.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823371c3-f3ed-4372-a11a-807b4285d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_shuffled_norm_xr = xr.DataArray(data=y_out_shuffled_norm.squeeze()).rename({'dim_0': 'index'})\n",
    "y_out_shuffled_norm_xr = y_out_shuffled_norm_xr.assign_coords({'index': x_val_norm.index,'dim_1': ['latitude','longitude']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa60df5-be6a-4261-9044-48c1e67f0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalise the output\n",
    "lat_out_shuffled = pp.denormalise_vars(y_out_shuffled_norm_xr.sel(dim_1='latitude'), \n",
    "                         norm_metrics['latitude'].loc['mean_vars'],\n",
    "                         norm_metrics['latitude'].loc['range_vars'])\n",
    "\n",
    "lon_out_shuffled = pp.denormalise_vars(y_out_shuffled_norm_xr.sel(dim_1='longitude'), \n",
    "                         norm_metrics['longitude'].loc['mean_vars'],\n",
    "                         norm_metrics['longitude'].loc['range_vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd38517-f96e-4e3b-b11c-f24d1b8463b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_out_pd_s_shuffled = pd.Series(lat_out_shuffled.values,index=latlon_val_norm.index,name='predicted_lat') \n",
    "lat_target_pd_s = pd.Series(lat_target.values,index=input_data_val_norm.index,name='reference_lat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b977417-0277-453d-b9a8-a93f454aa07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_out_pd_s_shuffled = pd.Series(lon_out_shuffled.values,index=latlon_val_norm.index,name='predicted_lon') \n",
    "lon_target_pd_s = pd.Series(lon_target.values,index=input_data_val_norm.index,name='reference_lon') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203e058-921c-4060-9548-b27cd3b3abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(((lat_out_pd_s_shuffled - lat_target_pd_s)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e589f2d-1e9a-4037-bbe2-918d18798e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(((lon_out_pd_s_shuffled - lon_target_pd_s)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fb65e-ddaf-433e-b4f2-32c7e7f84031",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(((lat_out_pd_s - lat_target_pd_s)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db3f63-1237-494d-ac0a-754f96ad39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(((lon_out_pd_s - lon_target_pd_s)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe14b9-6f57-4a5c-971a-86a18b988b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vv in x_val_norm['variable']:\n",
    "    shuffled_var = x_val_norm.sel(variable=vv).copy()\n",
    "    np.random.shuffle(shuffled_var.values)\n",
    "    x_val_norm_shuffled = xr.concat([x_val_norm.drop_sel(variable=vv.values).copy(),shuffled_var], dim='variable')\n",
    "    \n",
    "    model = keras.models.load_model(path_model + 'model_medium_latlon.h5')\n",
    "    y_out_shuffled_norm = model.predict(x_val_norm_shuffled.T.values)\n",
    "    y_out_shuffled_norm_xr = xr.DataArray(data=y_out_shuffled_norm.squeeze()).rename({'dim_0': 'index'})\n",
    "    y_out_shuffled_norm_xr = y_out_shuffled_norm_xr.assign_coords({'index': x_val_norm.index,'dim_1': ['latitude','longitude']})\n",
    "    \n",
    "    # denormalise the output\n",
    "    lat_out_shuffled = pp.denormalise_vars(y_out_shuffled_norm_xr.sel(dim_1='latitude'), \n",
    "                         norm_metrics['latitude'].loc['mean_vars'],\n",
    "                         norm_metrics['latitude'].loc['range_vars'])\n",
    "\n",
    "    lon_out_shuffled = pp.denormalise_vars(y_out_shuffled_norm_xr.sel(dim_1='longitude'), \n",
    "                         norm_metrics['longitude'].loc['mean_vars'],\n",
    "                         norm_metrics['longitude'].loc['range_vars'])\n",
    "    \n",
    "    lat_out_pd_s_shuffled = pd.Series(lat_out_shuffled.values,index=latlon_val_norm.index,name='predicted_lat') \n",
    "    lat_target_pd_s = pd.Series(lat_target.values,index=input_data_val_norm.index,name='reference_lat') \n",
    "    \n",
    "    lon_out_pd_s_shuffled = pd.Series(lon_out_shuffled.values,index=latlon_val_norm.index,name='predicted_lon') \n",
    "    lon_target_pd_s = pd.Series(lon_target.values,index=input_data_val_norm.index,name='reference_lon') \n",
    "    \n",
    "    print(vv.values)\n",
    "    print('Latitude RMSE:',np.sqrt(((lat_out_pd_s_shuffled - lat_target_pd_s)**2).mean()))\n",
    "    print('Longitude RMSE:',np.sqrt(((lon_out_pd_s_shuffled - lon_target_pd_s)**2).mean()))\n",
    "    plt.figure()\n",
    "    plt.scatter(lat_out_pd_s_shuffled.values,lat_target_pd_s.values,c='r',s=20,alpha=0.03)\n",
    "    plt.plot(yy,yy,'k-')\n",
    "    plt.title(vv.values)\n",
    "    plt.xlim(-90,-60)\n",
    "    plt.ylim(-90,-60)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(lon_out_pd_s_shuffled.values,lon_target_pd_s.values,c='b',s=20,alpha=0.03)\n",
    "    plt.plot(xx,xx,'k-')\n",
    "    plt.xlim(-180,180)\n",
    "    plt.ylim(-180,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6414eb4-1381-4074-9e7a-fbd40035d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f2430-7cac-4f02-9f72-63c5cb03512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_target_pd_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0289883a-c381-4b41-aff2-4bb1ff11016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_norm.drop_sel(variable=vv.values).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e811a0-fa48-418b-a5c0-c9f054896962",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e0710-aa10-418a-b3b4-74507b605c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnet",
   "language": "python",
   "name": "neuralnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

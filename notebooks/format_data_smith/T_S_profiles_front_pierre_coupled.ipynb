{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Jan 09 10:16 2023\n",
    "\n",
    "This is a script to cut out the T and S in the 50 km in front of the ice front for SMITH data\n",
    "\n",
    "@author: Clara Burgard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-think",
   "metadata": {},
   "source": [
    "- calculate the distance to the ice front for the small domain in front of the ice shelf\n",
    "- take the ocean points at distance of ~50 km of the ice front "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "import basal_melt_param.useful_functions as uf\n",
    "import basal_melt_param.T_S_profile_functions as tspf\n",
    "import basal_melt_param.melt_functions as meltf\n",
    "import basal_melt_param.box_functions as bf\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "import distributed\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(n_workers=8, dashboard_address=':8795', local_directory='/tmp', memory_limit='6GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-technical",
   "metadata": {},
   "source": [
    "READ IN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf02249-4960-461f-9a78-c91b904c4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run = 'EPM026'\n",
    "\n",
    "if nemo_run == 'OPM006':\n",
    "    yy_start = 1989\n",
    "    yy_end = 2018\n",
    "elif nemo_run == 'OPM021' or nemo_run == 'OPM026':\n",
    "    yy_start = 1989\n",
    "    yy_end = 2018\n",
    "elif nemo_run == 'OPM016' or nemo_run == 'OPM018':\n",
    "    yy_start = 1980\n",
    "    yy_end = 2008\n",
    "elif nemo_run == 'OPM027':\n",
    "    yy_start = 1999\n",
    "    yy_end = 2038\n",
    "elif nemo_run == 'OPM031':\n",
    "    yy_start = 1999\n",
    "    yy_end = 2068\n",
    "elif nemo_run == 'EPM031' or nemo_run=='EPM026':\n",
    "    yy_start = 2049\n",
    "    yy_end = 2058\n",
    "elif nemo_run == 'EPM034':\n",
    "    yy_start = 2119\n",
    "    yy_end = 2128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nemo_run[0] == 'O':\n",
    "    inputpath_data='/bettik/burgardc/SCRIPTS/basal_melt_param/data/interim/NEMO_eORCA025.L121_'+nemo_run+'_ANT_STEREO/'\n",
    "    inputpath_profiles='/bettik/burgardc/SCRIPTS/basal_melt_param/data/interim/T_S_PROF/nemo_5km_'+nemo_run+'/'\n",
    "    inputpath_isf='/bettik/burgardc/SCRIPTS/basal_melt_param/data/interim/ANTARCTICA_IS_MASKS/nemo_5km_'+nemo_run+'/'\n",
    "elif nemo_run[0] == 'E':\n",
    "    inputpath_data='/bettik/burgardc/DATA/NN_PARAM/interim/NEMO_eORCA025.L121_'+nemo_run+'_ANT_STEREO/'\n",
    "    inputpath_profiles='/bettik/burgardc/DATA/NN_PARAM/interim/T_S_PROF/nemo_5km_'+nemo_run+'/'\n",
    "    inputpath_isf='/bettik/burgardc/DATA/NN_PARAM/interim/ANTARCTICA_IS_MASKS/nemo_5km_'+nemo_run+'/'\n",
    "\n",
    "# make the domain a little smaller to make the computation even more efficient - file isf has already been made smaller at its creation\n",
    "map_lim = [-3000000,3000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-minnesota",
   "metadata": {},
   "source": [
    "PREPARE MASK AROUND FRONT (TO RUN WITHOUT DASK!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_isf_points_from_line_small_domain(isf_points_da,line_points_da):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the distance between ice shelf points and a line.\n",
    "    \n",
    "    This function computes the distance between ice shelf points and a line. This line can be the grounding\n",
    "    line or the ice shelf front.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    whole_domain : xarray.DataArray\n",
    "        ice-shelf mask - all ice shelves are represented by a number, all other points (ocean, land) set to nan\n",
    "    isf_points_da : xarray.DataArray\n",
    "        array containing only points from one ice shelf\n",
    "    line_points_da : xarray.DataArray\n",
    "        mask representing the grounding line or ice shelf front mask corresponding to the ice shelf selected in ``isf_points_da``\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    xr_dist_to_line : xarray.DataArray\n",
    "        distance of the each ice shelf point to the given line of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # add a common dimension 'grid' along which to stack\n",
    "    stacked_isf_points = isf_points_da.stack(grid=['y', 'x'])\n",
    "    stacked_line = line_points_da.stack(grid=['y', 'x'])\n",
    "    \n",
    "    # remove nans\n",
    "    filtered_isf_points = stacked_isf_points[stacked_isf_points>0]\n",
    "    filtered_line = stacked_line[stacked_line>0]\n",
    "    \n",
    "    # write out the y,x pairs behind the dimension 'grid'\n",
    "    grid_isf_points = filtered_isf_points.indexes['grid'].to_frame().values.astype(float)\n",
    "    grid_line = filtered_line.indexes['grid'].to_frame().values.astype(float)\n",
    "    \n",
    "    # create tree to line and compute distance\n",
    "    tree_line = cKDTree(grid_line)\n",
    "    dist_yx_to_line, _ = tree_line.query(grid_isf_points)\n",
    "        \n",
    "    # add the coordinates of the previous variables\n",
    "    xr_dist_to_line = filtered_isf_points.copy(data=dist_yx_to_line)\n",
    "    # put 1D array back into the format of the grid and put away the 'grid' dimension\n",
    "    xr_dist_to_line = xr_dist_to_line.unstack('grid')\n",
    "    \n",
    "    return xr_dist_to_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9ac38-3351-46ae-bf72-e33d0e9ac67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in tqdm(range(yy_start,yy_end+1)):\n",
    "#for tt in range(2049,2059):\n",
    "    print(tt)\n",
    "    \n",
    "    file_mask_orig = xr.open_mfdataset(inputpath_data+'other_mask_vars_Ant_stereo_'+str(tt)+'.nc')\n",
    "    file_mask = uf.cut_domain_stereo(file_mask_orig, map_lim, map_lim).load() #.chunk(chunks={'x': 50, 'y': 50})\n",
    "\n",
    "    # only points above 1500 m\n",
    "    contshelf = file_mask['bathy_metry'] <= 1500 # .drop('lon').drop('lat')    \n",
    "    \n",
    "    T_S_ocean_file = xr.open_dataset(inputpath_profiles+'T_S_theta_ocean_corrected_'+str(tt)+'.nc').load()\n",
    "    \n",
    "    file_isf_orig  = xr.open_dataset(inputpath_isf+'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(tt)+'.nc')\n",
    "    nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "    file_isf_nonnan = file_isf_orig.sel(Nisf=nonnan_Nisf)\n",
    "    large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "    file_isf = file_isf_nonnan.sel(Nisf=large_isf).load() #chunk(chunks={'x': 50, 'y': 50})\n",
    "    if 'labels' in file_isf.coords.keys():\n",
    "        file_isf = file_isf.drop('labels')\n",
    "    \n",
    "    lon = file_isf['longitude']\n",
    "    lat = file_isf['latitude']\n",
    "    \n",
    "    ocean = np.isfinite(T_S_ocean_file['theta_ocean'].isel(depth=0)).drop('depth')\n",
    "     \n",
    "    # NB: 5.0 x 1.75 is the effective resolution at 70S for a model of 1 degree resolution in longitude (assuming 5 delta X and a Mercator grid)\n",
    "    mask_50km = (ocean & contshelf).load()\n",
    "    \n",
    "    lon_box = np.array([10.0])\n",
    "    lat_box = np.array([3.5])\n",
    "\n",
    "    close_region_around_isf_mask = tspf.mask_boxes_around_IF_new(lon, lat, mask_50km, \n",
    "                                    file_isf['front_min_lon'], file_isf['front_max_lon'], \n",
    "                                    file_isf['front_min_lat'], file_isf['front_max_lat'],  \n",
    "                                    lon_box, lat_box, \n",
    "                                    file_isf['isf_name'])\n",
    "    \n",
    "    dist_list = [ ]\n",
    "    for kisf in file_isf['Nisf']:\n",
    "\n",
    "            if (file_isf['IF_mask']==kisf).sum() > 0:\n",
    "                region_to_cut_out = close_region_around_isf_mask.sel(Nisf=kisf).squeeze()\n",
    "                region_to_cut_out = region_to_cut_out.where(region_to_cut_out > 0, drop=True)\n",
    "                IF_region = file_isf['IF_mask'].where(file_isf['IF_mask']==kisf, drop=True)\n",
    "\n",
    "                dist_from_front = distance_isf_points_from_line_small_domain(region_to_cut_out,IF_region)\n",
    "                dist_list.append(dist_from_front)\n",
    "\n",
    "    dist_all = xr.concat(dist_list, dim='Nisf').reindex_like(file_isf)\n",
    "    dist_all.to_dataset(name='dist_from_front').to_netcdf(inputpath_profiles+'dist_to_ice_front_only_contshelf_'+str(tt)+'.nc')\n",
    "    \n",
    "    #del dist_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-flood",
   "metadata": {},
   "source": [
    "COMPUTING THE MEAN PROFILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-stamp",
   "metadata": {},
   "source": [
    "CONTINENTAL SHELF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9ee1d-da01-46da-8179-9d9d60513e92",
   "metadata": {},
   "source": [
    "(needs ~ 18 x 6 GB of memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_domain_distkm = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73658fa1-85c5-450a-b157-aecf1a09bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_front_file_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1167238-cb03-488c-847e-47f60016ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yy in tqdm(range(yy_start,yy_end+1)):\n",
    "    dist_to_front_file_yy = xr.open_dataset(inputpath_profiles+'dist_to_ice_front_only_contshelf_'+str(yy)+'.nc').chunk({'Nisf': 5})\n",
    "    T_S_ocean_file_yy = xr.open_dataset(inputpath_profiles+'T_S_theta_ocean_corrected_'+str(yy)+'.nc').chunk({'depth': 5})\n",
    "    \n",
    "    dist_to_front = dist_to_front_file_yy['dist_from_front']\n",
    "    mask_km = dist_to_front <= mask_domain_distkm\n",
    "    ds_sum = (T_S_ocean_file_yy * mask_km).sum(['x','y'])\n",
    "    \n",
    "    mask_depth = T_S_ocean_file_yy['salinity_ocean'].squeeze().drop('time') > 0\n",
    "    mask_all = mask_km & mask_depth\n",
    "    \n",
    "    mask_sum = mask_all.sum(['x','y'])\n",
    "    mask_sum = mask_sum.load()\n",
    "    \n",
    "    ds_mean = ds_sum/mask_sum\n",
    "    ds_mean.to_netcdf(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_'+str(yy)+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e854afc-5bff-475a-a251-261373704b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_list = []\n",
    "for tt in range(yy_start,yy_end+1):\n",
    "    ds_tt = xr.open_dataset(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_'+str(tt)+'.nc')\n",
    "    TS_list.append(ds_tt)\n",
    "TS_ds = xr.concat(TS_list, dim='time')\n",
    "TS_ds.to_netcdf(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_allyy.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6176c5b-c375-479f-b320-cdb427dcd0ec",
   "metadata": {},
   "source": [
    "THESE ARE REMNANTS OF TRYING WITH DASK BUT SOMEHOW DID NOT WORK :/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-retro",
   "metadata": {},
   "source": [
    "If workers don't die (with 12 cores, took approx 1hour), if workers die, divide work by years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbea70-58c9-4271-818b-d97a3db5dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dist_files = []\n",
    "list_temp_files = []\n",
    "range_time = range(5) #41\n",
    "for tt,yy in enumerate(range_time):\n",
    "    dist_to_front_file_yy = xr.open_mfdataset(inputpath_profiles+'dist_to_ice_front_only_contshelf_yy'+str(yy).zfill(2)+'.nc')\n",
    "    T_S_ocean_file_yy = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_yy'+str(yy).zfill(2)+'.nc')\n",
    "    if tt > 0:\n",
    "        dist_to_front_file = xr.concat([dist_to_front_file, dist_to_front_file_yy], dim='time').chunk({'x': 50, 'y': 50})\n",
    "        T_S_ocean_file = xr.concat([T_S_ocean_file, T_S_ocean_file_yy], dim='time').chunk({'x': 50, 'y': 50, 'depth': 50})\n",
    "    else:\n",
    "        dist_to_front_file = dist_to_front_file_yy.copy()\n",
    "        T_S_ocean_file = T_S_ocean_file_yy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98927f03-5f4a-4114-9575-f0cf86de51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_one = True # False if worker die, True if workers don't die\n",
    "if all_in_one:\n",
    "    dist_to_front_file = xr.open_mfdataset(list_dist_files, chunks={'x': 25, 'y': 25})\n",
    "    dist_to_front_file = dist_to_front_file.assign_coords({'time': range_time})\n",
    "    T_S_ocean_files = xr.open_mfdataset(list_temp_files, chunks={'x': 25, 'y': 25, 'depth': 50})\n",
    "    T_S_ocean_files = T_S_ocean_files.assign_coords({'time': range_time})\n",
    "#else:\n",
    "#    dist_to_front_file = xr.open_mfdataset(inputpath_profiles+'dist_to_ice_front_only_contshelf.nc',chunks={'x': 100, 'y': 100})\n",
    "#    T_S_ocean_files = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_*.nc', concat_dim='time', chunks={'x': 100, 'y': 100, 'depth': 50}, parallel=True)\n",
    "#    #T_S_ocean_1980 = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_1990.nc',chunks={'x': 100, 'y': 100, 'depth': 50})\n",
    "#    T_S_ocean_1980 = xr.open_mfdataset(inputpath_profiles+'T_S_theta_ocean_corrected_2000.nc',chunks={'x': 100, 'y': 100, 'depth': 50})\n",
    "dist_to_front = dist_to_front_file['dist_from_front']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-stockholm",
   "metadata": {},
   "source": [
    "Prepare sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bc40d-7470-4d3c-9209-d5a21967a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_front = dist_to_front_file['dist_from_front']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_km = dist_to_front <= mask_domain_distkm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f835e4c-9888-4eb2-92e3-74a17eaaf0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_S_ocean_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sum = (T_S_ocean_file * mask_km).sum(['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_in_one:\n",
    "    ds_sum = ds_sum.load()\n",
    "    #ds_sum.to_netcdf(inputpath_profiles+'ds_sum_for_mean.nc')\n",
    "    ds_sum.to_netcdf(inputpath_profiles+'ds_sum_for_mean_contshelf.nc')\n",
    "else:\n",
    "    yearly_datasets = list(tspf.split_by_chunks(ds_sum.unify_chunks(),'time'))\n",
    "    paths = [tspf.create_filepath(ds, 'ds_sum_for_mean_contshelf_yy', inputpath_profiles, ds.time[0].values) for ds in yearly_datasets]\n",
    "    xr.save_mfdataset(datasets=yearly_datasets, paths=paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-graph",
   "metadata": {},
   "source": [
    "Prepare number of points by which you divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_in_one:\n",
    "    ds_sum = xr.open_mfdataset(inputpath_profiles+'ds_sum_for_mean_contshelf.nc')\n",
    "else:\n",
    "    ds_sum = xr.open_mfdataset(inputpath_profiles+'ds_sum_for_mean_contshelf_*.nc', concat_dim='time', parallel=True).drop('profile_domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_depth = T_S_ocean_1980['salinity_ocean'].squeeze().drop('time') >0\n",
    "mask_all = mask_km & mask_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sum = mask_all.sum(['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sum = mask_sum.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-dividend",
   "metadata": {},
   "source": [
    "Make the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean = ds_sum/mask_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017240a3-741c-4283-90d6-7fbbc4946498",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean.drop('profile_domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_mean = ds_mean.rename({'dist_from_front': 'profile_domain'})\n",
    "ds_mean = ds_mean.drop('profile_domain').rename({'dist_from_front': 'profile_domain'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_mean.to_netcdf(inputpath_profiles+'T_S_mean_prof_km_1980-2018.nc')\n",
    "ds_mean.to_netcdf(inputpath_profiles+'T_S_mean_prof_corrected_km_contshelf_1980-2018.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad737307-ffbf-4d95-9fdb-6f781d9661ba",
   "metadata": {},
   "source": [
    "FINISHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "kisf = 21\n",
    "\n",
    "old_profiles['theta_ocean'].sel(Nisf=kisf).isel(dist_from_front=0).mean('time').plot(color='r',linestyle='--')\n",
    "old_profiles['theta_ocean'].sel(Nisf=kisf).isel(dist_from_front=1).mean('time').plot(color='g',linestyle='--')\n",
    "old_profiles['theta_ocean'].sel(Nisf=kisf).isel(dist_from_front=2).mean('time').plot(color='b',linestyle='--')\n",
    "old_profiles['theta_ocean'].sel(Nisf=kisf).isel(dist_from_front=3).mean('time').plot(color='orange',linestyle='--')\n",
    "\n",
    "new_profiles['theta_ocean'].sel(Nisf=kisf).isel(profile_domain=0).mean('time').plot(color='r')\n",
    "new_profiles['theta_ocean'].sel(Nisf=kisf).isel(profile_domain=1).mean('time').plot(color='g')\n",
    "new_profiles['theta_ocean'].sel(Nisf=kisf).isel(profile_domain=2).mean('time').plot(color='b')\n",
    "new_profiles['theta_ocean'].sel(Nisf=kisf).isel(profile_domain=3).mean('time').plot(color='orange')\n",
    "#new_profiles['theta_ocean'].sel(Nisf=kisf).isel(profile_domain=4).mean('time').plot(color='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "kisf = 10\n",
    "\n",
    "old_profiles['salinity_ocean'].sel(Nisf=kisf).isel(dist_from_front=0).mean('time').plot(color='r',linestyle='--')\n",
    "old_profiles['salinity_ocean'].sel(Nisf=kisf).isel(dist_from_front=1).mean('time').plot(color='g',linestyle='--')\n",
    "old_profiles['salinity_ocean'].sel(Nisf=kisf).isel(dist_from_front=2).mean('time').plot(color='b',linestyle='--')\n",
    "old_profiles['salinity_ocean'].sel(Nisf=kisf).isel(dist_from_front=3).mean('time').plot(color='orange',linestyle='--')\n",
    "\n",
    "new_profiles['salinity_ocean'].sel(Nisf=kisf).isel(profile_domain=0).mean('time').plot(color='r')\n",
    "new_profiles['salinity_ocean'].sel(Nisf=kisf).isel(profile_domain=1).mean('time').plot(color='g')\n",
    "new_profiles['salinity_ocean'].sel(Nisf=kisf).isel(profile_domain=2).mean('time').plot(color='b')\n",
    "new_profiles['salinity_ocean'].sel(Nisf=kisf).isel(profile_domain=3).mean('time').plot(color='orange')\n",
    "new_profiles['salinity_ocean'].sel(Nisf=kisf).isel(profile_domain=4).mean('time').plot(color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-profit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

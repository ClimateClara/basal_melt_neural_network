{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5dfe2-7fa8-458b-a30c-e0a11be8d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Feb 01 15:27 2023\n",
    "\n",
    "Try permute and predict with Smith data\n",
    "\n",
    "Author: @claraburgard\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731f235-1948-4d8e-8bca-d6206005bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import time\n",
    "import os,sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "from basal_melt_neural_networks.constants import *\n",
    "import basal_melt_neural_networks.diagnostic_functions as diag\n",
    "import basal_melt_neural_networks.data_formatting as dfmt\n",
    "import basal_melt_neural_networks.postprocessing_functions as pp\n",
    "from basal_melt_param.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f4e29-fb3b-4ccc-bde5-b82d18e40cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9625ca-6f3d-4c7b-ad41-625d54472bcf",
   "metadata": {},
   "source": [
    "DEFINE OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ce0dc-b22d-4f8f-b178-3b74e9dd35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_size =  'small' #'mini', 'small', 'medium', 'large', 'extra_large'\n",
    "TS_opt = 'extrap' # extrap, whole, thermocline\n",
    "norm_method =  'std' # std, interquart, minmax\n",
    "exp_name = 'newbasic2'#'onlyTSdraftandslope' #'onlyTSdraftandslope' #'TSdraftbotandiceddandwcd' #'onlyTSisfdraft' #'TSdraftbotandiceddandwcdreldGL' #TSdraftslopereldGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f0c23-e5d0-46d9-8768-4c946ef70b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_vars = ['dGL','dIF','corrected_isfdraft','bathy_metry','slope_bed_lon','slope_bed_lat','slope_ice_lon','slope_ice_lat','isfdraft_conc','theta_in','salinity_in','u_tide']\n",
    "if exp_name == 'onlyTSdraft':\n",
    "    input_vars = ['corrected_isfdraft','theta_in','salinity_in']\n",
    "elif exp_name == 'TSdraftbotandiceddandwcd':\n",
    "    input_vars = ['corrected_isfdraft','theta_in','salinity_in','water_col_depth','theta_bot','salinity_bot']\n",
    "elif exp_name == 'TSdraftbotandiceddandwcdreldGL':\n",
    "    input_vars = ['corrected_isfdraft','theta_in','salinity_in','water_col_depth','theta_bot','salinity_bot','rel_dGL']\n",
    "elif exp_name == 'onlyTSdraftandslope':\n",
    "    input_vars = ['corrected_isfdraft','theta_in','salinity_in','slope_ice_lon','slope_ice_lat']\n",
    "elif exp_name == 'onlyTSdraft2':\n",
    "    input_vars = ['corrected_isfdraft','theta_in','salinity_in']\n",
    "elif exp_name == 'TSTfdGLdIFwcd':\n",
    "    input_vars = ['corrected_isfdraft','theta_in','salinity_in','dGL','dIF','slope_ice_lon','slope_ice_lat','water_col_depth']\n",
    "elif exp_name == 'TSdraftslopereldGL':\n",
    "    input_vars = ['corrected_isfdraft','theta_in','salinity_in','slope_ice_lon','slope_ice_lat','rel_dGL']\n",
    "elif exp_name == 'allbutconstants':\n",
    "    input_vars = ['dGL','dIF','corrected_isfdraft','bathy_metry','slope_bed_lon','slope_bed_lat','slope_ice_lon','slope_ice_lat',\n",
    "                'isfdraft_conc','theta_in','salinity_in','u_tide']\n",
    "elif exp_name == 'newbasic':\n",
    "    input_vars = ['dGL','dIF','corrected_isfdraft','bathy_metry','slope_bed_lon','slope_bed_lat','slope_ice_lon','slope_ice_lat',\n",
    "                'theta_in','salinity_in']\n",
    "elif exp_name == 'newbasic2':\n",
    "    input_vars = ['dGL','dIF','corrected_isfdraft','bathy_metry','slope_bed_lon','slope_bed_lat','slope_ice_lon','slope_ice_lat',\n",
    "                'theta_in','salinity_in','T_mean', 'S_mean', 'T_std', 'S_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f4d74-0233-4f73-b86d-8bb723b40cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run = 'bf663'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da86c9-9c12-48b6-9668-b285afa3f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#isf_dim = [10,11,12,13,18,22,23,24,25,30,31,33,38,39,40,42,43,44,45,47,48,51,52,53,54,55,58,61,65,66,69,70,71,73,75]\n",
    "#isf_dim = [10,11,12,13,18,22,23,25,30,31,33,39,40,42,43,44,45,47,51,55,58,61,65,66,69,70,71,73,75] # for bi646\n",
    "#isf_dim = [10,11,12,13,18,22,23,25,30,31,33,39,40,42,43,44,45,47,51,55,58,61,65,66,69,70,71,73,75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54666cc3-7f68-4d51-bc27-1bf2acc53e52",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad98a6-8d8a-4ae9-a160-d3c800d4ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data_nn = '/bettik/burgardc/DATA/NN_PARAM/interim/INPUT_DATA/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b2ac3-134f-49bf-a409-fe1ad93be78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TS_opt == 'extrap':\n",
    "    inputpath_CVinput = inputpath_data_nn+'EXTRAPOLATED_ISFDRAFT_CHUNKS/'\n",
    "    inputpath_csv = inputpath_data_nn+'SMITH_'+nemo_run+'_EXTRAPDRAFT_CHUNKS/'\n",
    "elif TS_opt == 'whole':\n",
    "    inputpath_CVinput = inputpath_data_nn+'WHOLE_PROF_CHUNKS_CV/'\n",
    "    path_orig_data = inputpath_data_nn+'WHOLE_PROF_CHUNKS/'\n",
    "elif TS_opt == 'thermocline':\n",
    "    inputpath_CVinput = inputpath_data_nn+'THERMOCLINE_CHUNKS_CV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d4b4e-8205-45fd-b2ff-6deed9631b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lim = [-3000000,3000000]\n",
    "inputpath_data='/bettik/burgardc/DATA/NN_PARAM/interim/SMITH_'+nemo_run+'/'\n",
    "file_other = xr.open_dataset(inputpath_data+'corrected_draft_bathy_isf.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_other_cut = dfmt.cut_domain_stereo(file_other, map_lim, map_lim)\n",
    "file_conc = xr.open_dataset(inputpath_data+'isfdraft_conc_Ant_stereo.nc')\n",
    "file_conc_cut = dfmt.cut_domain_stereo(file_conc, map_lim, map_lim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5c411-a489-4b3a-bbc8-6d2fcc75100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_evalmetrics_NN_yy(nemo_run, tt, file_conc, file_other):\n",
    "    inputpath_boxes = '/bettik/burgardc/DATA/NN_PARAM/interim/BOXES/SMITH_'+nemo_run+'/'\n",
    "    inputpath_data='/bettik/burgardc/DATA/NN_PARAM/interim/SMITH_'+nemo_run+'/'\n",
    "    inputpath_mask='/bettik/burgardc/DATA/NN_PARAM/interim/ANTARCTICA_IS_MASKS/SMITH_'+nemo_run+'/'\n",
    "    \n",
    "    file_isf_orig = xr.open_dataset(inputpath_mask+'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(tt)+'.nc').drop('time')\n",
    "    #file_isf = file_isf_orig.sel(Nisf=isf_list)\n",
    "    nonnan_Nisf = file_isf_orig['Nisf'].where(np.isfinite(file_isf_orig['front_bot_depth_max']), drop=True).astype(int)\n",
    "    file_isf_nonnan = file_isf_orig.sel(Nisf=nonnan_Nisf)\n",
    "    large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "    file_isf = file_isf_nonnan.sel(Nisf=large_isf)\n",
    "    if 'labels' in file_isf.coords.keys():\n",
    "        file_isf = file_isf.drop('labels')\n",
    "    \n",
    "    file_other_cut = file_other.sel(time=tt)\n",
    "    file_conc_cut = file_conc.sel(time=tt)\n",
    "\n",
    "    ice_draft_pos = file_other_cut['corrected_isfdraft']\n",
    "    \n",
    "    box_charac_2D = xr.open_dataset(inputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS_'+str(tt)+'_merged75.nc')\n",
    "    box_charac_1D = xr.open_dataset(inputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS_'+str(tt)+'_merged75.nc')\n",
    "    \n",
    "    isf_stack_mask = dfmt.create_stacked_mask(file_isf['ISF_mask'], file_isf.Nisf, ['y','x'], 'mask_coord')\n",
    "\n",
    "    file_isf_conc = file_conc_cut['isfdraft_conc']\n",
    "\n",
    "    xx = file_isf.x\n",
    "    yy = file_isf.y\n",
    "    dx = (xx[2] - xx[1]).values\n",
    "    dy = (yy[2] - yy[1]).values\n",
    "    grid_cell_area = abs(dx*dy)  \n",
    "    grid_cell_area_weighted = file_isf_conc * grid_cell_area\n",
    "    \n",
    "    geometry_info_2D = xr.merge([ice_draft_pos.rename('ice_draft_pos'),\n",
    "                            grid_cell_area_weighted.rename('grid_cell_area_weighted'),\n",
    "                            file_isf_conc])\n",
    "    \n",
    "    return file_isf, geometry_info_2D, box_charac_2D, box_charac_1D, isf_stack_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53a31c-6c70-4c42-babc-7e9306017cf1",
   "metadata": {},
   "source": [
    "PREPARE FILES WITH EVERYTHING AND SHUFFLE THEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e604e45-9e5b-4a3b-b58c-5b853a6c70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "startyy = 1980\n",
    "endyy = 1980 + 60\n",
    "n=0\n",
    "\n",
    "\n",
    "\n",
    "for tt in tqdm(range(startyy,endyy)):\n",
    "    file_isf, geometry_info_2D, box_charac_2D, box_charac_1D, isf_stack_mask = pp.read_input_evalmetrics_NN_yy(nemo_run, tt, file_conc_cut, file_other_cut)\n",
    "\n",
    "    for kisf in file_isf.Nisf.values:\n",
    "        df_nrun = pd.read_csv(inputpath_csv + 'dataframe_input_isf'+str(kisf).zfill(3)+'_'+str(tt).zfill(2)+'_'+nemo_run+'.csv')#.drop(['x', 'y'])\n",
    "        if n == 0:\n",
    "            print('here')\n",
    "            df_list = df_nrun#.reset_index(drop=True, inplace=True)\n",
    "        else:\n",
    "            df_list = df_list.append(df_nrun) #.drop(['x', 'y'], axis=1, inplace=True))\n",
    "        n = n+1\n",
    "\n",
    "df_list.to_csv(inputpath_csv + 'dataframe_input_allisf_'+str(startyy)+'-'+str(endyy)+'_'+nemo_run+'.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca577c-5486-4212-ae07-0a26727f27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "startyy = 1980 \n",
    "endyy = 1980 + 60\n",
    "df_list_orig = pd.read_csv(inputpath_csv + 'dataframe_input_allisf_'+str(startyy)+'-'+str(endyy)+'_'+nemo_run+'.csv')\n",
    "shuffled_df = df_list_orig.sample(frac=1, random_state=1)\n",
    "shuffled_df.to_csv(inputpath_csv + 'dataframe_shuffledinput_allisf_'+str(startyy)+'-'+str(endyy)+'_'+nemo_run+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb2945-d5c0-4803-a66b-da63e99116c9",
   "metadata": {},
   "source": [
    "COMBINE ALL DATA TO SHUFFLE (BOTH SMITH RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ef1c1-936d-42b2-b594-2ce66b778c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "startyy = 1980 \n",
    "endyy = 1980 + 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e20484-bf73-439a-8cbd-7923b3716c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bf663 = pd.read_csv(inputpath_data_nn+'SMITH_bf663_EXTRAPDRAFT_CHUNKS/dataframe_shuffledinput_allisf_'+str(startyy)+'-'+str(endyy)+'_bf663.csv')\n",
    "data_bi646 = pd.read_csv(inputpath_data_nn+'SMITH_bi646_EXTRAPDRAFT_CHUNKS/dataframe_shuffledinput_allisf_'+str(startyy)+'-'+str(endyy)+'_bi646.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937ed9e-f82c-4d27-a963-e6ce6646d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(inputpath_data_nn+'BOTH_SMITHS/dataframe_shuffledinput_allisf_'+str(startyy)+'-'+str(endyy)+'_bf663andbi646.csv','a') as f:\n",
    "    for df in [data_bf663,data_bi646]:\n",
    "        df.to_csv(f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a01c43-c582-44d8-8098-8fcefb2c7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_both = pd.read_csv(inputpath_data_nn+'BOTH_SMITHS/dataframe_shuffledinput_allisf_'+str(startyy)+'-'+str(endyy)+'_bf663andbi646.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d7611-cd3a-4f1e-9405-efbb0dd80466",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671091e2-cb12-4923-ac5b-3af102c55023",
   "metadata": {},
   "source": [
    "APPLY 1D MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0920d-223c-4f92-9df5-7d577c1080ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue with u_tide\n",
    "outputpath_melt_nn = '/bettik/burgardc/DATA/NN_PARAM/processed/MELT_RATE/SMITH_'+nemo_run+'/'\n",
    "path_model = '/bettik/burgardc/DATA/NN_PARAM/interim/NN_MODELS/experiments/WHOLE/'\n",
    "\n",
    "startyy = 1980\n",
    "endyy = 1980 + 30\n",
    "\n",
    "df_shuffled = pd.read_csv(inputpath_csv + 'dataframe_shuffledinput_allisf_'+str(startyy)+'-'+str(endyy)+'_'+nemo_run+'.csv')\n",
    "\n",
    "#for vv in ['dGL']: \n",
    "for vv in input_vars: \n",
    "    print(vv)\n",
    "    \n",
    "    res_1D_allyy_list = []\n",
    "    for tt in tqdm(range(startyy,endyy + 1)):\n",
    "    #for tt in tqdm([1970]):\n",
    "\n",
    "        file_isf, geometry_info_2D, box_charac_2D, box_charac_1D, isf_stack_mask = read_input_evalmetrics_NN_yy(nemo_run, tt, file_conc_cut, file_other_cut)\n",
    "\n",
    "        res_1D_list = []\n",
    "        for kisf in file_isf.Nisf.values:  \n",
    "        #for kisf in [66]:  \n",
    "\n",
    "\n",
    "            norm_metrics_file = xr.open_dataset(inputpath_CVinput + 'metrics_norm_wholedataset.nc')\n",
    "            #norm_metrics_file_addvar1 = xr.open_dataset(inputpath_CVinput + 'metrics_norm_addvar1_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "            #norm_metrics_file_addvar1 = norm_metrics_file_addvar1.drop('salinity_in')\n",
    "            #norm_metrics_file = xr.merge([norm_metrics_file_orig,norm_metrics_file_addvar1])\n",
    "            norm_metrics = norm_metrics_file.sel(norm_method=norm_method).drop('norm_method').to_dataframe()\n",
    "\n",
    "            df_nrun = pd.read_csv(inputpath_csv + 'dataframe_input_isf'+str(kisf).zfill(3)+'_'+str(tt)+'_'+nemo_run+'.csv',index_col=[0,1])\n",
    "            #df_nrun_addvar1 = pd.read_csv(path_orig_data + 'dataframe_addvar1_isf'+str(kisf).zfill(3)+'_'+str(tblock_out).zfill(3)+'.csv',index_col=[0,1,2])\n",
    "            #df_nrun_addvar1 = df_nrun_addvar1.drop(['salinity_in'], axis=1)\n",
    "            #df_nrun = pd.concat([df_nrun_orig,df_nrun_addvar1],join = 'outer', axis = 1)\n",
    "            \n",
    "            nrows = len(df_nrun.index)\n",
    "            shuffled_var = df_shuffled[vv].sample(n=nrows).values\n",
    "            df_nrun_in_shuffled = df_nrun.drop(vv, axis=1).copy()\n",
    "            df_nrun_in_shuffled[vv] = shuffled_var\n",
    "            \n",
    "            ens_res2D_list = []\n",
    "            for seed_nb in range(1,11):\n",
    "                model = keras.models.load_model(path_model + 'model_nn_'+mod_size+'_'+exp_name+'_wholedataset_'+str(seed_nb).zfill(2)+'_TS'+TS_opt+'_norm'+norm_method+'.h5')\n",
    "\n",
    "                res_2D = pp.apply_NN_results_2D_1isf_1tblock(file_isf, norm_metrics, df_nrun_in_shuffled, model, input_vars)\n",
    "\n",
    "                ens_res2D_list.append(res_2D.assign_coords({'seed_nb': seed_nb}))\n",
    "\n",
    "            xr_ens_res2D = xr.concat(ens_res2D_list, dim='seed_nb')\n",
    "            xr_ensmean_res2D = xr_ens_res2D.mean('seed_nb')\n",
    "            \n",
    "            if box_charac_2D and box_charac_1D:\n",
    "                box_loc_config2 = box_charac_2D['box_location'].sel(box_nb_tot=box_charac_1D['nD_config'].sel(config=2))\n",
    "                box1 = box_loc_config2.where(box_loc_config2==1).isel(Nisf=0).drop('Nisf')\n",
    "\n",
    "            geometry_isf_2D = dfmt.choose_isf(geometry_info_2D,isf_stack_mask, kisf)\n",
    "            melt_rate_2D_isf_m_per_y = dfmt.choose_isf(xr_ensmean_res2D,isf_stack_mask, kisf)\n",
    "\n",
    "            melt_rate_1D_isf_Gt_per_y = (melt_rate_2D_isf_m_per_y * geometry_isf_2D['grid_cell_area_weighted']).sum(dim=['mask_coord']) * rho_i / 10**12\n",
    "\n",
    "            box_loc_config_stacked = dfmt.choose_isf(box1, isf_stack_mask, kisf)\n",
    "            param_melt_2D_box1_isf = melt_rate_2D_isf_m_per_y.where(np.isfinite(box_loc_config_stacked))\n",
    "\n",
    "            melt_rate_1D_isf_myr_box1_mean = dfmt.weighted_mean(param_melt_2D_box1_isf,['mask_coord'], geometry_isf_2D['isfdraft_conc'])     \n",
    "\n",
    "            out_1D = xr.concat([melt_rate_1D_isf_Gt_per_y, melt_rate_1D_isf_myr_box1_mean], dim='metrics').assign_coords({'metrics': ['Gt','box1']})\n",
    "\n",
    "            res_1D_list.append(out_1D)\n",
    "\n",
    "        res_1D_all = xr.concat(res_1D_list, dim='Nisf')\n",
    "        res_1D_allyy_list.append(res_1D_all)\n",
    "\n",
    "    res_1D_allyy = xr.concat(res_1D_allyy_list, dim='time')\n",
    "\n",
    "    res_1D_allyy.to_netcdf(outputpath_melt_nn + 'evalmetrics_shuffled'+vv+'_1D_'+mod_size+'_'+exp_name+'_ensmean_'+TS_opt+'_norm'+norm_method+'_allyy_'+nemo_run+'.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906edfce-6176-4194-ac8f-8d9acca8bd56",
   "metadata": {},
   "source": [
    "GROUP SOME OF THE SHUFFLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1315db-9e40-4e91-aecb-8c14b2125f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue with u_tide\n",
    "outputpath_melt_nn = '/bettik/burgardc/DATA/NN_PARAM/processed/MELT_RATE/SMITH_'+nemo_run+'/'\n",
    "path_model = '/bettik/burgardc/DATA/NN_PARAM/interim/NN_MODELS/experiments/WHOLE/'\n",
    "\n",
    "if nemo_run == 'bf663':\n",
    "    df_shuffled = pd.read_csv(inputpath_csv + 'dataframe_shuffledinput_allisf_timeuntil40_'+nemo_run+'.csv')\n",
    "elif nemo_run == 'bi646':\n",
    "    df_shuffled = pd.read_csv(inputpath_csv + 'dataframe_shuffledinput_allisf_timeuntil35_'+nemo_run+'.csv')\n",
    "\n",
    "groups_list = ['position','watercolumn','bathy_geometry','ice_geometry','water_properties']\n",
    "\n",
    "for groupvv in groups_list:\n",
    "    \n",
    "    print(groupvv)\n",
    "    if groupvv == 'position':\n",
    "        var_of_int = ['dGL','dIF']\n",
    "    elif groupvv == 'watercolumn':\n",
    "        var_of_int = ['corrected_isfdraft','bathy_metry']\n",
    "    elif groupvv == 'bathy_geometry':\n",
    "        var_of_int = ['bathy_metry','slope_bed_lon','slope_bed_lat']\n",
    "    elif groupvv == 'ice_geometry':\n",
    "        var_of_int = ['corrected_isfdraft','slope_ice_lon','slope_ice_lat']\n",
    "    elif groupvv == 'water_properties':\n",
    "        var_of_int = ['theta_in','salinity_in']\n",
    "    \n",
    "    res_1D_allyy_list = []\n",
    "    for tt in tqdm(tblock_dim):\n",
    "    #for tt in tqdm([1970]):\n",
    "        isf_out = 0\n",
    "        tblock_out = 5\n",
    "\n",
    "        file_isf, geometry_info_2D, box_charac_2D, box_charac_1D, isf_stack_mask = read_input_evalmetrics_NN_yy(nemo_run, tt, isf_dim)\n",
    "\n",
    "        res_1D_list = []\n",
    "        for kisf in isf_dim:  \n",
    "        #for kisf in [66]:  \n",
    "\n",
    "\n",
    "            norm_metrics_file = xr.open_dataset(inputpath_CVinput + 'metrics_norm_wholedataset.nc')\n",
    "            #norm_metrics_file_addvar1 = xr.open_dataset(inputpath_CVinput + 'metrics_norm_addvar1_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "            #norm_metrics_file_addvar1 = norm_metrics_file_addvar1.drop('salinity_in')\n",
    "            #norm_metrics_file = xr.merge([norm_metrics_file_orig,norm_metrics_file_addvar1])\n",
    "            norm_metrics = norm_metrics_file.sel(norm_method=norm_method).drop('norm_method').to_dataframe()\n",
    "\n",
    "            df_nrun = pd.read_csv(inputpath_csv + 'dataframe_input_isf'+str(kisf).zfill(3)+'_'+str(tt)+'_'+nemo_run+'.csv',index_col=[0,1])\n",
    "            #df_nrun_addvar1 = pd.read_csv(path_orig_data + 'dataframe_addvar1_isf'+str(kisf).zfill(3)+'_'+str(tblock_out).zfill(3)+'.csv',index_col=[0,1,2])\n",
    "            #df_nrun_addvar1 = df_nrun_addvar1.drop(['salinity_in'], axis=1)\n",
    "            #df_nrun = pd.concat([df_nrun_orig,df_nrun_addvar1],join = 'outer', axis = 1)\n",
    "\n",
    "            model = keras.models.load_model(path_model + 'model_nn_'+mod_size+'_'+exp_name+'_wholedataset_TS'+TS_opt+'_norm'+norm_method+'.h5')\n",
    "            \n",
    "            nrows = len(df_nrun.index)\n",
    "            shuffled_var = df_shuffled[var_of_int].sample(n=nrows).values\n",
    "            df_nrun_in_shuffled = df_nrun.drop(var_of_int, axis=1).copy()\n",
    "            df_nrun_in_shuffled[var_of_int] = shuffled_var\n",
    "\n",
    "            res_1D = pp.evalmetrics_1D_NN(kisf, norm_metrics, df_nrun_in_shuffled, model, file_isf, geometry_info_2D, box_charac_2D, box_charac_1D, isf_stack_mask, input_vars)    \n",
    "            res_1D_list.append(res_1D)\n",
    "\n",
    "        res_1D_all = xr.concat(res_1D_list, dim='Nisf')\n",
    "        res_1D_allyy_list.append(res_1D_all)\n",
    "\n",
    "    res_1D_allyy = xr.concat(res_1D_allyy_list, dim='time')\n",
    "\n",
    "    res_1D_allyy.to_netcdf(outputpath_melt_nn + 'evalmetrics_shuffled'+groupvv+'_1D_'+mod_size+'_'+exp_name+'_'+TS_opt+'_norm'+norm_method+'_allyy_'+nemo_run+'.nc')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18341ff-f9ff-4989-bb6a-88d03f6c0b8f",
   "metadata": {},
   "source": [
    "APPLY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c26cb3-7424-401d-8bc7-43ce2971af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### use any model from CV over time\n",
    "outputpath_melt_nn = '/bettik/burgardc/DATA/NN_PARAM/processed/MELT_RATE/SMITH_'+nemo_run+'/'\n",
    "path_model = '/bettik/burgardc/DATA/NN_PARAM/interim/NN_MODELS/experiments/WHOLE/'\n",
    "\n",
    "#for tt in tqdm(tblock_dim):\n",
    "for tt in tqdm([1970]):\n",
    "    \n",
    "    file_isf, geometry_info_2D, box_charac_2D, box_charac_1D, isf_stack_mask = read_input_evalmetrics_NN_yy(nemo_run, tt, isf_dim)\n",
    "    \n",
    "    res_2D_shuffled = []\n",
    "    for vv in ['dGL','dIF']: #, 'dIF','corrected_isfdraft', 'bathy_metry', 'slope_bed_lon',\n",
    "               #'slope_bed_lat', 'slope_ice_lon', 'slope_ice_lat',\n",
    "               #'entry_depth_max', 'isfdraft_conc', 'u_tide', 'theta_in', 'salinity_in']:\n",
    "        print(vv)\n",
    "        \n",
    "        res_2D_all = None\n",
    "        #for kisf in isf_dim: \n",
    "        for kisf in [66]:\n",
    "            \n",
    "            norm_metrics_file = xr.open_dataset(inputpath_CVinput + 'metrics_norm_wholedataset.nc')\n",
    "            #norm_metrics_file_addvar1 = xr.open_dataset(inputpath_CVinput + 'metrics_norm_addvar1_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "            #norm_metrics_file_addvar1 = norm_metrics_file_addvar1.drop('salinity_in')\n",
    "            #norm_metrics_file = xr.merge([norm_metrics_file_orig,norm_metrics_file_addvar1])\n",
    "            norm_metrics = norm_metrics_file.sel(norm_method=norm_method).drop('norm_method').to_dataframe()\n",
    "\n",
    "            df_nrun = pd.read_csv(inputpath_csv + 'dataframe_input_isf'+str(kisf).zfill(3)+'_'+str(tt).zfill(2)+'_'+nemo_run+'.csv',index_col=[0,1])\n",
    "            #df_nrun_addvar1 = pd.read_csv(path_orig_data + 'dataframe_addvar1_isf'+str(kisf).zfill(3)+'_'+str(tblock_out).zfill(3)+'.csv',index_col=[0,1,2])\n",
    "            #df_nrun_addvar1 = df_nrun_addvar1.drop(['salinity_in'], axis=1)\n",
    "            #df_nrun = pd.concat([df_nrun_orig,df_nrun_addvar1],join = 'outer', axis = 1)\n",
    "\n",
    "            model = keras.models.load_model(path_model + 'model_nn_'+mod_size+'_'+exp_name+'_wholedataset_TS'+TS_opt+'_norm'+norm_method+'.h5')\n",
    "            \n",
    "            shuffled_var = df_nrun[vv].copy()\n",
    "            np.random.shuffle(shuffled_var.values)\n",
    "            df_nrun_in_shuffled = df_nrun.drop(vv, axis=1).copy()\n",
    "            df_nrun_in_shuffled[vv] = shuffled_var\n",
    "            #res_2D_shuffled = pp.apply_NN_results_2D_1isf_1tblock(file_isf, norm_metrics, df_nrun_in_shuffled, model, input_vars)\n",
    "            res_2D = pp.apply_NN_results_2D_1isf_1tblock(file_isf, norm_metrics, df_nrun_in_shuffled, model, input_vars)\n",
    "\n",
    "            if res_2D_all is None:\n",
    "                res_2D_all = res_2D\n",
    "            else:\n",
    "                res_2D_all = res_2D_all.combine_first(res_2D)\n",
    "        res_2D_shuffled.append(res_2D_all.assign_coords({'shuffle_dim': vv}))\n",
    "        \n",
    "    res_2D_shuffled_all = xr.concat(res_2D_shuffled, dim='shuffle_dim')        \n",
    "    #res_2D_all.to_netcdf(outputpath_melt_nn + 'evalmetrics_2D_'+mod_size+'_'+exp_name+'_'+TS_opt+'_norm'+norm_method+'_'+str(tt)+'_'+nemo_run+'_shuffled.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce3f73-c910-473f-a72d-aef82a962f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt((((res_1D_allyy['predicted_melt'] - res_1D_allyy['reference_melt']).sel(metrics='Gt'))**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d95013-1f54-4db3-b2fe-b7e73dea2199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnet",
   "language": "python",
   "name": "neuralnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da078-92be-4065-80e4-706de1f9698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Apr 15 09:53 2022\n",
    "\n",
    "Apply model coming from train_DNN_with_prepared_input.ipynb on one other run\n",
    "\n",
    "Author: @claraburgard\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475db9f2-93ee-45d2-b132-fb9128757f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import time\n",
    "import os,sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "from basal_melt_neural_networks.constants import *\n",
    "import basal_melt_neural_networks.diagnostic_functions as diag\n",
    "import basal_melt_neural_networks.data_formatting as dfmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912d910-10dc-4041-85ad-58a51157d27d",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e629462-b3d5-452f-8b30-b3ef4c313920",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data = '/bettik/burgardc/DATA/NN_PARAM/interim/INPUT_DATA/'\n",
    "outputpath_melt_nn = '/bettik/burgardc/DATA/NN_PARAM/processed/MELT_RATE/'\n",
    "outputpath_nn_models = '/bettik/burgardc/DATA/NN_PARAM/interim/NN_MODELS/'\n",
    "outputpath_doc = '/bettik/burgardc/SCRIPTS/basal_melt_neural_networks/custom_doc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c925f-4114-41d7-8d5f-5d48fad0a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run0 = 'OPM021' #['OPM006', 'OPM016', 'OPM018', 'OPM021', 'OPM026', 'OPM027', 'OPM031-1', OPM031-2']\n",
    "if nemo_run0 in ['OPM031-1','OPM031-2']:\n",
    "    nemo_run = 'OPM031'\n",
    "else:\n",
    "    nemo_run = nemo_run0\n",
    "    \n",
    "inputpath_mask = '/bettik/burgardc/SCRIPTS/basal_melt_param/data/interim/ANTARCTICA_IS_MASKS/nemo_5km_'+nemo_run+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867b63e-803b-4e05-a692-4bea9060736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_isf = xr.open_dataset(inputpath_mask+'nemo_5km_isf_masks_and_info_and_distance_new.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1e018-9baf-458c-bfce-5a8ea86ea1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "isf_list = [10, 11, 12, 13, 18, 21, 22, 23, 24, 25, 30, 31, 33, 38, 39, \n",
    "            40, 42, 43, 44, 45, 47, 48, 51, 52, 53, 54, 55, 58, 61, 65, \n",
    "            66, 69, 70, 71, 73, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb0bfa-143f-4fe3-9f08-846cb0e8d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['dGL', 'dIF', 'corrected_isfdraft', 'bathy_metry', 'slope_bed_lon',\n",
    "       'slope_bed_lat', 'slope_ice_lon', 'slope_ice_lat', 'isf_area',\n",
    "       'entry_depth_max', 'isfdraft_conc', 'u_tide', 'T_001', 'T_002',\n",
    "       'T_003', 'T_004', 'T_005', 'T_006', 'T_007', 'T_008', 'T_009',\n",
    "       'T_010', 'T_011', 'T_012', 'T_013', 'T_014', 'T_015', 'T_016',\n",
    "       'T_017', 'T_018', 'T_019', 'T_020', 'T_021', 'T_022', 'T_023',\n",
    "       'T_024', 'T_025', 'T_026', 'T_027', 'T_028', 'T_029', 'T_030',\n",
    "       'T_031', 'T_032', 'T_033', 'T_034', 'T_035', 'T_036', 'T_037',\n",
    "       'T_038', 'T_039', 'T_040', 'T_041', 'T_042', 'T_043', 'T_044',\n",
    "       'T_045', 'T_046', 'T_047', 'T_048', 'T_049', 'T_050', 'T_051',\n",
    "       'T_052', 'T_053', 'T_054', 'T_055', 'T_056', 'T_057', 'T_058',\n",
    "       'T_059', 'T_060', 'T_061', 'T_062', 'T_063', 'T_064', 'T_065',\n",
    "       'T_066', 'T_067', 'T_068', 'S_001', 'S_002', 'S_003', 'S_004',\n",
    "       'S_005', 'S_006', 'S_007', 'S_008', 'S_009', 'S_010', 'S_011',\n",
    "       'S_012', 'S_013', 'S_014', 'S_015', 'S_016', 'S_017', 'S_018',\n",
    "       'S_019', 'S_020', 'S_021', 'S_022', 'S_023', 'S_024', 'S_025',\n",
    "       'S_026', 'S_027', 'S_028', 'S_029', 'S_030', 'S_031', 'S_032',\n",
    "       'S_033', 'S_034', 'S_035', 'S_036', 'S_037', 'S_038', 'S_039',\n",
    "       'S_040', 'S_041', 'S_042', 'S_043', 'S_044', 'S_045', 'S_046',\n",
    "       'S_047', 'S_048', 'S_049', 'S_050', 'S_051', 'S_052', 'S_053',\n",
    "       'S_054', 'S_055', 'S_056', 'S_057', 'S_058', 'S_059', 'S_060',\n",
    "       'S_061', 'S_062', 'S_063', 'S_064', 'S_065', 'S_066', 'S_067',\n",
    "       'S_068', 'water_column']\n",
    "\n",
    "for shuff_var in var_list:\n",
    "\n",
    "    for timetag in ['20220427-1051']:\n",
    "\n",
    "        new_path_output = outputpath_melt_nn+timetag+'/'\n",
    "        if not os.path.isdir(new_path_output):\n",
    "            print(\"I did not find this folder \"+timetag+\") so I created a new one, I hope that's ok!\")\n",
    "            os.mkdir(new_path_output)\n",
    "        else:\n",
    "            print(\"This folder (\"+timetag+\") exists already!\")\n",
    "\n",
    "        new_path_model = outputpath_nn_models+timetag+'/'\n",
    "        if not os.path.isdir(new_path_model):\n",
    "            print(\"I did not find this folder (\"+timetag+\") in model folder so I created a new one, I hope that's ok!\")\n",
    "\n",
    "        print(timetag)\n",
    "        if timetag in ['20220427-0957','20220427-1052','20220427-1058','20220427-1059']:\n",
    "            timetag_data = '20220427-0957'\n",
    "            path_data = inputpath_data+'EXTRAPOLATED_ISFDRAFT/'\n",
    "\n",
    "        elif timetag in ['20220427-1002','20220427-1021','20220427-1042','20220427-1051']:\n",
    "            timetag_data = '20220427-1002'\n",
    "            path_data = inputpath_data+'WHOLE_PROF/'\n",
    "\n",
    "\n",
    "        norm_data_path = outputpath_nn_models+timetag_data+'/'\n",
    "\n",
    "        normalisation_coeff = xr.open_dataset(norm_data_path+ 'dataset_norm_training_factors_'+timetag_data+'.nc')\n",
    "        model = keras.models.load_model(new_path_model + 'model_nn_'+timetag+'.h5')\n",
    "\n",
    "        y_all_isf = None\n",
    "\n",
    "        for kisf in tqdm(isf_list): \n",
    "\n",
    "            ### READ DATA\n",
    "            df_nrun = pd.read_csv(path_data + 'dataframe_input_isf'+str(kisf).zfill(3)+'_'+nemo_run0+'.csv',index_col=[0,1,2])\n",
    "            clean_df_nrun_kisf = pd.read_csv(path_data + 'dataframe_input_isf'+str(kisf).zfill(3)+'_'+nemo_run0+'.csv',index_col=[0,1,2])\n",
    "            clean_df_nrun_kisf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            new_df = clean_df_nrun_kisf\n",
    "            if shuff_var == 'water_column':\n",
    "                shuffled_df = new_df[['corrected_isfdraft', 'bathy_metry']].copy().sample(frac=1, random_state=1)\n",
    "                new_df['corrected_isfdraft'] = shuffled_df['corrected_isfdraft'].values\n",
    "                new_df['bathy_metry'] = shuffled_df['bathy_metry'].values\n",
    "            else:\n",
    "                shuffled_df = new_df[shuff_var].copy().sample(frac=1, random_state=1)\n",
    "                new_df[shuff_var] = shuffled_df.values\n",
    "\n",
    "            new_df = new_df.to_xarray()\n",
    "\n",
    "            normalisation_coeff_input = normalisation_coeff.drop_vars(['melt_m_ice_per_y'])\n",
    "            normalised_vars = (new_df.drop_vars(['melt_m_ice_per_y']) - normalisation_coeff_input.sel(metric='mean_vars'))/normalisation_coeff_input.sel(metric='std_vars')\n",
    "\n",
    "            input_var = normalised_vars.to_array().load()\n",
    "            ref_melt = new_df['melt_m_ice_per_y'].load()\n",
    "\n",
    "            ### RUN THE MODEL\n",
    "            y_out_norm = model.predict(input_var.T.values)\n",
    "            y_out_norm_xr = xr.DataArray(data=y_out_norm.squeeze()).rename({'dim_0': 'index'})\n",
    "            y_out_norm_xr = y_out_norm_xr.assign_coords({'index': input_var.index})\n",
    "            y_out = (y_out_norm_xr * normalisation_coeff['melt_m_ice_per_y'].sel(metric='std_vars')) + normalisation_coeff['melt_m_ice_per_y'].sel(metric='mean_vars')\n",
    "\n",
    "            y_out_pd_s = pd.Series(y_out.values,index=df_nrun.index,name='predicted_melt') \n",
    "            y_target_pd_s = pd.Series(ref_melt.values,index=df_nrun.index,name='reference_melt') \n",
    "\n",
    "            ### PUT SOME ORDER IN THE FILE\n",
    "            y_out_xr = y_out_pd_s.to_xarray()\n",
    "            y_target_xr = y_target_pd_s.to_xarray()\n",
    "            y_to_compare = xr.merge([y_out_xr.T, y_target_xr.T]).sortby('y')\n",
    "\n",
    "            y_whole_grid = y_to_compare.reindex_like(file_isf['ISF_mask'])\n",
    "            if y_all_isf is None:\n",
    "                y_all_isf = y_whole_grid\n",
    "            else:\n",
    "                y_all_isf = y_all_isf.combine_first(y_whole_grid)\n",
    "\n",
    "        y_all_isf.to_netcdf(new_path_output+'NN_melt_predicted_reference_m_ice_per_yr_'+nemo_run0+'_shuffled'+shuff_var+'.nc')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fd49e-f3c8-4bd2-b9ca-299b4c5ad64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[shuff_var].sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525b076-3b09-4b26-9a5d-04960f49144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timetag in ['20220427-1051']:\n",
    "    \n",
    "    new_path_output = outputpath_melt_nn+timetag+'/'\n",
    "    nn_output_m_ice_per_y = xr.open_dataset(new_path_output+'NN_melt_predicted_reference_m_ice_per_yr_'+nemo_run0+'_shuffled'+shuff_var+'.nc')\n",
    "\n",
    "    tuning_mode = False\n",
    "    nisf_list = file_isf.Nisf\n",
    "\n",
    "    if verbose:\n",
    "        time_start = time.time()\n",
    "        print('WELCOME! AS YOU WISH, I WILL COMPUTE THE EVALUATION METRICS FOR '+str(len(nisf_list))+' ICE SHELVES')\n",
    "\n",
    "    if verbose:\n",
    "        list_loop = tqdm(nisf_list)\n",
    "    else:\n",
    "        list_loop = nisf_list\n",
    "\n",
    "    if box_charac_2D and box_charac_1D:\n",
    "        box_loc_config2 = box_charac_2D['box_location'].sel(box_nb_tot=box_charac_1D['nD_config'].sel(config=2))\n",
    "        box1 = box_loc_config2.where(box_loc_config2==1).isel(Nisf=0).drop('Nisf')\n",
    "    #elif not box_charac_2D:\n",
    "    #    return print('You have not given me the 2D box characteristics! :( ')\n",
    "    #elif not box_charac_1D:\n",
    "    #    return print('You have not given me the 1D box characteristics! :( ')\n",
    "\n",
    "    melt1D_Gt_per_yr_list = []\n",
    "    if not tuning_mode:\n",
    "        melt1D_myr_box1_list = []\n",
    "\n",
    "    for kisf in list_loop:\n",
    "        #print(kisf, n)\n",
    "        geometry_isf_2D = dfmt.choose_isf(geometry_info_2D,isf_stack_mask, kisf)\n",
    "        melt_rate_2D_isf_m_per_y = dfmt.choose_isf(nn_output_m_ice_per_y['predicted_melt'].reindex_like(file_isf['ISF_mask']),isf_stack_mask, kisf)\n",
    "\n",
    "        melt_rate_1D_isf_Gt_per_y = (melt_rate_2D_isf_m_per_y * geometry_isf_2D['grid_cell_area_weighted']).sum(dim=['mask_coord']) * rho_i / 10**12\n",
    "        melt1D_Gt_per_yr_list.append(melt_rate_1D_isf_Gt_per_y)\n",
    "\n",
    "        if not tuning_mode:\n",
    "            box_loc_config_stacked = dfmt.choose_isf(box1, isf_stack_mask, kisf)\n",
    "            param_melt_2D_box1_isf = melt_rate_2D_isf_m_per_y.where(np.isfinite(box_loc_config_stacked))\n",
    "\n",
    "            melt_rate_1D_isf_myr_box1_mean = dfmt.weighted_mean(param_melt_2D_box1_isf,['mask_coord'], geometry_isf_2D['isfdraft_conc'])     \n",
    "            melt1D_myr_box1_list.append(melt_rate_1D_isf_myr_box1_mean)\n",
    "\n",
    "    melt1D_Gt_per_yr = xr.concat(melt1D_Gt_per_yr_list, dim='Nisf')\n",
    "    if not tuning_mode:\n",
    "        melt1D_myr_box1 = xr.concat(melt1D_myr_box1_list, dim='Nisf')\n",
    "\n",
    "    melt1D_Gt_per_yr_ds = melt1D_Gt_per_yr.to_dataset(name='melt_1D_Gt_per_y')\n",
    "    if not tuning_mode:\n",
    "        melt1D_myr_box1_ds = melt1D_myr_box1.to_dataset(name='melt_1D_mean_myr_box1')\n",
    "        out_1D = xr.merge([melt1D_Gt_per_yr_ds, melt1D_myr_box1_ds])\n",
    "    else:\n",
    "        out_1D = melt1D_Gt_per_yr_ds\n",
    "\n",
    "    if verbose:\n",
    "        timelength = time.time() - time_start\n",
    "        print(\"I AM DONE! IT TOOK: \"+str(round(timelength,2))+\" seconds.\")\n",
    "\n",
    "    out_1D.to_netcdf(new_path_output+'eval_metrics_'+nemo_run0+'_shuffled'+shuff_var+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b8bfb-d615-4bac-be9d-005db5d160e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130fb4e1-ce1a-409c-8b2a-c343f9f0e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_all_isf['predicted_melt'],y_all_isf['reference_melt'], alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a596f-db1a-498c-b2d1-3dfc0ae4257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## OLD STUFF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnet",
   "language": "python",
   "name": "neuralnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
